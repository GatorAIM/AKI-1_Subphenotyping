{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50222126-1c23-4908-bbaa-2bdb96c583d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "pd.set_option(\"...\", None)\n",
    "%store -r ct_names\n",
    "%store -r raw_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a589e19-7ff1-4717-a9cf-fe9f98e5c9fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_path = \"...\"\n",
    "ct_names = [\"...\", \"...\", \"...\", \"...\", \"...\", \"...\", \"...\", \"...\"]\n",
    "%store raw_path\n",
    "%store ct_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2047b8-58a1-4b14-a703-ed817ba7be60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pat_id_cols = [\"...\", \"...\",  \"...\"]\n",
    "%store pat_id_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc7c5bf-ce99-4f24-a518-0271b055eac4",
   "metadata": {},
   "source": [
    "# Read AKI and Non-AKI Patient Hospitalization Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b295266d-c38e-4731-93af-9c31c73c89ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_and_format_onsets(ct_names, raw_path):\n",
    "    print(\"...\")\n",
    "    onset_dict = read_onsets(ct_names, raw_path)\n",
    "    processed_onset_dict = format_onest_dict(onset_dict)\n",
    "    \n",
    "    for ct_name, onset_df in processed_onset_dict.items():\n",
    "        print(\"...\" %(ct_name, len(onset_df.ONSETS_ENCOUNTERID)))\n",
    "        \n",
    "    onset_df = concat_dfs_to_one(processed_onset_dict)\n",
    "    return onset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000a2456-af64-4c6a-919f-f6fce7bded4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_dfs_to_one(info_dict):\n",
    "    dfs_to_concat = []\n",
    "    for df in info_dict.values():\n",
    "        dfs_to_concat.append(df)\n",
    "    one_df = pd.concat(dfs_to_concat, axis = 0)\n",
    "    return one_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33749969-c148-4fa7-8e57-9a797b3c419d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_onsets(ct_names, raw_path):\n",
    "    onset_dict = dict()\n",
    "    use_cols = [\"...\", \"...\", \"...\", \"...\"]\n",
    "    \n",
    "    for ct_name in ct_names:\n",
    "\n",
    "        data_path = get_data_path(ct_name, raw_path)\n",
    "            \n",
    "        if (ct_name == \"...\") or (ct_name == \"...\") or (ct_name == \"...\"):\n",
    "            onset_df = pd.read_csv(data_path + \"...\", delimiter = \"...\", usecols = use_cols)\n",
    "            \n",
    "        elif (ct_name == \"...\"):\n",
    "            onset_df = pd.read_csv(data_path + \"...\", delimiter = \"...\", usecols = use_cols)\n",
    "            \n",
    "        elif (ct_name == \"...\"):\n",
    "            onset_df = pd.read_csv(data_path + \"...\", delimiter = \"...\")\n",
    "            onset_df.columns = [col.upper() for col in onset_df.columns] \n",
    "            onset_df = onset_df[use_cols]\n",
    "            \n",
    "        elif (ct_name == \"...\"):\n",
    "            onset_df = pd.read_csv(data_path + \"...\", delimiter = \"...\", usecols = use_cols)\n",
    "            \n",
    "        elif (ct_name == \"...\"):\n",
    "            onset_df = pd.read_csv(data_path + \"...\", delimiter = \"...\", usecols = use_cols)\n",
    "            \n",
    "        elif (ct_name == \"...\"):\n",
    "            onset_df = pd.read_csv(data_path + \"...\", delimiter = \"...\")\n",
    "            onset_cols = onset_df.columns.tolist()\n",
    "            onset_cols = [s[:-len(\"...\"...\"...\")] \\\n",
    "                              if s.endswith(\"...\"...\"...\") else s for s in onset_cols]\n",
    "            onset_df.columns = onset_cols\n",
    "            onset_df = onset_df[use_cols]\n",
    "            \n",
    "        onset_dict[ct_name] = onset_df\n",
    "\n",
    "    return onset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5e8757-5c1a-4000-ada0-98e362c0fa51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_path(ct_name, raw_path):\n",
    "    if ct_name == \"...\":\n",
    "        data_path = raw_path + \"...\" + \"...\"\n",
    "    else:\n",
    "        data_path = raw_path + ct_name + \"...\"\n",
    "    return data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9923fe47-4e26-4896-a35c-584677320083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_onest_dict(onset_dict):\n",
    "    processed_onset_dict = dict()\n",
    "    for ct_name, onset_df in onset_dict.items():    \n",
    "        #convert id columns to string\n",
    "        onset_df[\"...\"] = onset_df[\"...\"].astype(str)\n",
    "        onset_df[\"...\"] = onset_df[\"...\"].astype(str)\n",
    "        onset_df.rename(columns={\"...\": \"...\"}, inplace = True) \n",
    "        \n",
    "        # Converting string data type into datetime object\n",
    "        onset_df[\"...\"] = pd.to_datetime(onset_df[\"...\"], format=\"...\")\n",
    "        onset_df[\"...\"] = pd.to_datetime(onset_df[\"...\"], format=\"...\")\n",
    "        \n",
    "        onset_df[\"...\"] = ct_name\n",
    "        processed_onset_dict[ct_name] = onset_df\n",
    "    return processed_onset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbcde83-e87a-417e-940c-1425cfe3d4cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "onset_df = read_and_format_onsets(ct_names, raw_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a21623-46ac-4e83-8dbd-d387f62e54e7",
   "metadata": {},
   "source": [
    "# Read  SCr Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c23dcf1-dfa4-4971-a9ed-7d7b66209bdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_and_format_SCR(ct_names, raw_path):\n",
    "    SCR_dict = read_SCR(ct_names, raw_path)\n",
    "    processed_SCR_dict = format_SCR_dict(SCR_dict)\n",
    "    SCR_df = concat_dfs_to_one(processed_SCR_dict)\n",
    "    return SCR_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43d7dbb-bb91-4211-9d46-373ba16082bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read Scr records, here we only kept the historical records(DAYS_SINCE_ADMIT < 0)\n",
    "def read_SCR(ct_names, raw_path):\n",
    "    SCR_dict = dict()\n",
    "    use_cols = [\"...\",\"...\",\"...\",\"...\",\"...\", \"...\"]\n",
    "\n",
    "    for ct_name in tqdm(ct_names):\n",
    "        \n",
    "        data_path = get_data_path(ct_name, raw_path)\n",
    "        \n",
    "        if (ct_name == \"...\") or (ct_name == \"...\") or (ct_name == \"...\"):\n",
    "            SCR_df = pd.read_csv(data_path + \"...\", delimiter = \"...\", usecols=use_cols)\n",
    "        elif (ct_name == \"...\"):\n",
    "            SCR_df = pd.read_csv(data_path + \"...\", delimiter = \"...\", usecols=use_cols)\n",
    "        elif (ct_name == \"...\"):\n",
    "            SCR_df = pd.read_csv(data_path + \"...\", delimiter = \"...\")\n",
    "            SCR_df.columns = [col.upper() for col in SCR_df.columns] \n",
    "            SCR_df = SCR_df[use_cols]\n",
    "        elif (ct_name == \"...\"):\n",
    "            SCR_df = pd.read_csv(data_path + \"...\", delimiter = \"...\", usecols=use_cols)\n",
    "        elif (ct_name == \"...\"):\n",
    "            SCR_df = pd.read_csv(data_path + \"...\", delimiter = \"...\", usecols=use_cols)\n",
    "        elif (ct_name == \"...\"):\n",
    "            SCR_df = pd.read_csv(data_path + \"...\", delimiter = \"...\")\n",
    "            SCR_cols = SCR_df.columns.tolist()\n",
    "            SCR_cols = [s[:-len(\"...\"+PD.DATE_SHIFT\"...\")] \\\n",
    "                              if s.endswith(\"...\"+PD.DATE_SHIFT\"...\") else s for s in SCR_cols]\n",
    "            SCR_df.columns = SCR_cols\n",
    "            SCR_df = SCR_df[use_cols]\n",
    "\n",
    "        SCR_dict[ct_name] = SCR_df\n",
    "        \n",
    "    return SCR_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93ab487-d02d-4df9-8f46-0419a8aece45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_SCR_dict(SCR_dict):\n",
    "    processed_SCR_dict = dict()\n",
    "    for ct_name, SCR_df in tqdm(SCR_dict.items()):\n",
    "        SCR_df[\"...\"] = SCR_df[\"...\"].astype(str)\n",
    "        SCR_df[[\"...\", \"...\"]] = SCR_df[[\"...\", \"...\"]].astype(str)\n",
    "        SCR_df[\"...\"] = pd.to_datetime(SCR_df[\"...\"], format=\"...\")\n",
    "        if ct_name == \"...\":\n",
    "            SCR_df[\"...\"] = SCR_df[\"...\"].dt.date\n",
    "            SCR_df[\"...\"] = pd.to_datetime(SCR_df[\"...\"])\n",
    "        SCR_df[\"...\"] = ct_name\n",
    "        processed_SCR_dict[ct_name] = SCR_df\n",
    "    return processed_SCR_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e4cc9d-e4c8-40d4-a5c6-5d7c18d3b54e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCR_df = read_and_format_SCR(ct_names, raw_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df050f58-fc8c-4908-8a15-1c3aad852ac0",
   "metadata": {},
   "source": [
    "# Merge Hospitalization Records with SCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25169cf-eb20-4d3e-923f-8886ebe10c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important: here we do not merge on encounter id, that is each encounter of each patient will be matched to\n",
    "# all SCr measurements this patient had\n",
    "complete_df = onset_df.merge(SCR_df[[\"...\", \"...\", \"...\", \"...\"]], \n",
    "                             on = [\"...\", \"...\"], how = \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6155ff2-d289-4e54-b83d-8be13d0eb5da",
   "metadata": {},
   "source": [
    "# Compute SCR Baseline Based on 7-day SCr Prior to Admission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b3b4c5-6b41-4e8f-9e55-f1ee5a665576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#SCr within 24 hour after admission, that is admission day and one day after, get mean\n",
    "admission_SCr = complete_df[(complete_df.SPECIMEN_DATE >= complete_df.ADMIT_DATE) & \\\n",
    "                            (complete_df.SPECIMEN_DATE <= (complete_df.ADMIT_DATE + pd.Timedelta(days=1)))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bb7328-3603-4e88-8cda-12aa2f0af717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Admission SCr is the mean of all the SCr within 24h admission\n",
    "admission_SCr = admission_SCr.groupby(pat_id_cols)[\"...\"].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fab3ed1-479c-4837-b2eb-ad555e1eb6ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "admission_SCr.rename(columns = {\"...\": \"...\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd473e49-250d-4a46-8fad-3ffdc5a3067c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#merge the ADMISSION_SCR back to the main frame\n",
    "complete_df = complete_df.merge(admission_SCr, on = pat_id_cols, how = \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045f30ee-4df7-4813-8312-66b2c549e938",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_missing_percentage_without_dup(df, col_to_check, id_col):\n",
    "    n_unique = len(df[id_col].unique())\n",
    "    n_nan_rows = len(df[df[col_to_check].isna()][id_col].unique())\n",
    "    return (n_nan_rows, n_nan_rows / n_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c451325-e3d5-4d80-ab24-5b8807b71a0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# how many encounters do not have admission SCr level?\n",
    "check_missing_percentage_without_dup(complete_df, \"...\", \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e706d385-b43d-4d5c-9758-18bc6233df82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#SCr within 7 days prior to admission\n",
    "one_week_prior_admission = complete_df[(complete_df.SPECIMEN_DATE >= complete_df.ADMIT_DATE - pd.Timedelta(days=7)) & \\\n",
    "                                 (complete_df.SPECIMEN_DATE < complete_df.ADMIT_DATE)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d691f2-f34e-4149-9dfc-baaddc0b4d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sort based on speciment date and group and take the last record\n",
    "one_week_prior_admission = one_week_prior_admission.sort_values(by = pat_id_cols + [\"...\"], ascending = True)\n",
    "one_week_prior_admission = one_week_prior_admission.groupby(pat_id_cols)[\"...\"].last().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d2ee4b-ab24-47eb-962d-f7099820f7d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "one_week_prior_admission.rename(columns = {\"...\": \"...\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bf11bc-a4ce-4058-abf2-f200d0b1473e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "complete_df = complete_df.merge(one_week_prior_admission, on = pat_id_cols, how = \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9001fa0-8b36-47ba-ab33-8c0e7c07107a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# how many encounters do not have 7-day prior SCr level?\n",
    "check_missing_percentage_without_dup(complete_df, \"...\", \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b3fdfe-7a08-4528-a8d7-81fe408888bb",
   "metadata": {},
   "source": [
    "# If No Prior 7-day SCr, Use One-year SCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b128b0c-9035-4189-9983-cdb53d425f86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#SCr within 7 days - 365 days prior to admission\n",
    "one_year_prior_admission = complete_df[(complete_df.SPECIMEN_DATE >= complete_df.ADMIT_DATE - pd.Timedelta(days=365)) & \\\n",
    "                                 (complete_df.SPECIMEN_DATE < complete_df.ADMIT_DATE- pd.Timedelta(days=7))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b40cf9a-cb21-4798-b651-99b61e13f6d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 7 - 365 SCr records mean\n",
    "one_year_prior_admission = one_year_prior_admission.groupby(pat_id_cols)[\"...\"].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8264e6-a66a-4293-a291-87821775dd3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "one_year_prior_admission.rename(columns = {\"...\": \"...\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45b8a54-e1be-4b5f-b48a-3bbabd125a41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "complete_df = complete_df.merge(one_year_prior_admission, on = pat_id_cols, how = \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f57eba3-c56a-4ae6-99fb-d4a5a2378a8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# how many encoutner do not have one year SCr level?\n",
    "check_missing_percentage_without_dup(complete_df, \"...\", \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2217137d-29df-467d-9545-384506b683ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# how many encoutner do not have both one week and one year SCr level?\n",
    "n_unique = len(complete_df[\"...\"].unique())\n",
    "n_nan_rows = len(complete_df[(complete_df[\"...\"].isna()) & (complete_df[\"...\"].isna())][\"...\"].unique())\n",
    "(n_nan_rows, n_nan_rows / n_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89625c5-da96-4220-b1c9-840ee634d2ef",
   "metadata": {},
   "source": [
    "# Apply Baseline for Patients with Computed SCR records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5367a1-4763-4f7e-b931-9ae352ae96b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for patients without history records but with admission SCr,\n",
    "# we do not use admission SCr as baseline\n",
    "complete_df[\"...\"] = np.where(\n",
    "    pd.notnull(complete_df[\"...\"]),\n",
    "    np.minimum(complete_df[\"...\"], complete_df[\"...\"]),\n",
    "    np.minimum(complete_df[\"...\"], complete_df[\"...\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b0a923-a731-4421-8b1f-d14ae34ec907",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_missing_percentage_without_dup(complete_df, \"...\", \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1edf55f-7c5c-45c4-8599-a3eee3e6840d",
   "metadata": {},
   "source": [
    "# Estimate SCR Baseline for Encounters without Any History Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4baf27-baf0-4767-a0db-0e175849ae95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc_to_MDRD = complete_df.loc[complete_df.BASELINE_SCR_RECORD.isna(), \n",
    "                              pat_id_cols + [\"...\", \"...\"]].copy(deep = True)\n",
    "#one patient one row\n",
    "enc_to_MDRD.drop_duplicates(subset = pat_id_cols, keep=\"...\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0725a07-f4cb-4e07-ad22-f81bcd8a753b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc_to_MDRD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d398d83-01b6-4bc0-92a2-e6ad69b104d6",
   "metadata": {},
   "source": [
    "MDRD for non-CKD patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf0145a-17b3-45bf-a4fe-27afa34e5fa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_and_format_DX(ct_names, raw_path, pat_df):\n",
    "    DX_dict = read_DX(ct_names, raw_path)\n",
    "    processed_DX_dict = format_DX_dict(DX_dict, pat_df)\n",
    "    DX_df = concat_dfs_to_one(processed_DX_dict)\n",
    "    return DX_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2432973c-d5a5-40be-9e1c-5d3f9697a763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read patients' diagnosis data\n",
    "def read_DX(ct_names, raw_path):\n",
    "    DX_dict = dict()\n",
    "    use_cols = [\"...\", \"...\", \"...\", \"...\", \"...\", \"...\"]\n",
    "    ct_missing_DX_DATE = [\"...\", \"...\", \"...\"]\n",
    "    \n",
    "    for ct_name in tqdm(ct_names):\n",
    "        \n",
    "        data_path = get_data_path(ct_name, raw_path)\n",
    "        \n",
    "        if (ct_name == \"...\") or (ct_name == \"...\") or (ct_name == \"...\"):\n",
    "            DX_df = pd.read_csv(data_path + \"...\", delimiter = \"...\", usecols=use_cols)\n",
    "            \n",
    "            #adjust the col order of UIOWA\n",
    "            if ct_name == \"...\":\n",
    "                DX_df = DX_df[use_cols]\n",
    "                \n",
    "        elif (ct_name == \"...\"):\n",
    "            DX_df = pd.read_csv(data_path + \"...\", delimiter = \"...\", usecols=use_cols)\n",
    "            \n",
    "        elif (ct_name == \"...\"):\n",
    "            DX_df = pd.read_csv(data_path + \"...\", delimiter = \"...\")\n",
    "            DX_df.columns = [col.upper() for col in DX_df.columns] \n",
    "            DX_df = DX_df[use_cols]\n",
    "            \n",
    "        elif (ct_name == \"...\"):\n",
    "            DX_df = pd.read_csv(data_path + \"...\", delimiter = \"...\", usecols=use_cols)\n",
    "            \n",
    "        elif (ct_name == \"...\"):\n",
    "            DX_df = pd.read_csv(data_path + \"...\", delimiter = \"...\", header=None, \n",
    "                                           skiprows = 1, usecols=[0, 2, 6, 8, 9, 20])\n",
    "            DX_df.columns = use_cols\n",
    "            \n",
    "        elif (ct_name == \"...\"):\n",
    "            DX_df = pd.read_csv(data_path + \"...\", delimiter = \"...\")\n",
    "            DX_cols = DX_df.columns.tolist()\n",
    "            DX_cols = [s[:-len(\"...\"+PD.DATE_SHIFT\"...\")] \\\n",
    "                              if s.endswith(\"...\"+PD.DATE_SHIFT\"...\") else s for s in DX_cols]\n",
    "            DX_df.columns = DX_cols\n",
    "            DX_df = DX_df[use_cols]\n",
    "            \n",
    "        DX_dict[ct_name] = DX_df\n",
    "        \n",
    "    return DX_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeb190f-1960-44e2-9ff7-0b50ea0cbe9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_DX_dict(DX_dict, pat_df):\n",
    "    processed_DX_dict = dict()\n",
    "    ct_missing_DX_DATE = [\"...\", \"...\", \"...\"]\n",
    "    \n",
    "    for ct_name, DX_df in tqdm(DX_dict.items()):\n",
    "        DX_df[\"...\"] = DX_df[\"...\"].astype(str)\n",
    "        pat_ct_df = pat_df[pat_df.CENTER_NAME == ct_name]\n",
    "        pat_ct_df = pat_ct_df.merge(DX_df[[\"...\", \"...\", \"...\", \"...\", \"...\"]], \n",
    "                                    on = \"...\", how = \"...\")\n",
    "        pat_ct_df.dropna(subset=[\"...\"], inplace = True)\n",
    "        \n",
    "        if ct_name not in ct_missing_DX_DATE:\n",
    "            pat_ct_df[\"...\"] = pd.to_datetime(pat_ct_df[\"...\"], format = \"...\")\n",
    "            pat_ct_df[\"...\"] = pat_ct_df[\"...\"].dt.strftime(\"...\")\n",
    "            pat_ct_df[\"...\"] = pd.to_datetime(pat_ct_df[\"...\"], format = \"...\")\n",
    "        else:\n",
    "            pat_ct_df.loc[:, \"...\"] = pat_ct_df.loc[:, \"...\"] + \\\n",
    "            pd.to_timedelta(pat_ct_df.loc[:, \"...\"], unit=\"...\")\n",
    "\n",
    "        #make type consistent\n",
    "        pat_ct_df = pat_ct_df[pat_ct_df.DX_DATE < pat_ct_df.ADMIT_DATE]\n",
    "        pat_ct_df[\"...\"] = pat_ct_df[\"...\"].astype(str)\n",
    "        pat_ct_df[\"...\"] = pat_ct_df[\"...\"].replace(\"...\", \"...\")\n",
    "        pat_ct_df[\"...\"] = pat_ct_df[\"...\"].replace(\"...\", \"...\")\n",
    "        pat_ct_df[\"...\"] = pat_ct_df[\"...\"].replace(\"...\", \"...\")\n",
    "        pat_ct_df = pat_ct_df[[\"...\", \"...\", \"...\", \n",
    "                              \"...\", \"...\", \"...\"]]\n",
    "        processed_DX_dict[ct_name] = pat_ct_df\n",
    "        \n",
    "    return processed_DX_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577dd138-edca-4ea1-839d-2f1e033af6d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DX_df = read_and_format_DX(ct_names, raw_path, enc_to_MDRD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268d9387-4c50-4a13-b35d-9e240079ce04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# again, we do not limit DX on specific encounter\n",
    "DX_df.drop(\"...\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e8a38e-85f8-4e4b-9d24-d8e846f76f43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc_to_MDRD_DX = enc_to_MDRD.merge(DX_df, on = [\"...\", \"...\"], how = \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e97c9f9-bec6-4404-b206-ec2941174ae1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# require DX is before admission (i.e. comorbidities)\n",
    "enc_to_MDRD_DX = enc_to_MDRD_DX[enc_to_MDRD_DX.DX_DATE < enc_to_MDRD_DX.ADMIT_DATE].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a25a4d-2757-47fa-a6ed-e9991d2cf4b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encounters with CKD without any history records\n",
    "ICD9_CKD = [\"...\", \"...\", \"...\", \"...\", \"...\", \"...\"]\n",
    "ICD10_CKD = [\"...\", \"...\", \"...\", \"...\", \"...\", \"...\"]\n",
    "enc_to_MDRD_CKD = enc_to_MDRD_DX[((enc_to_MDRD_DX.DX.isin(ICD9_CKD)) & (enc_to_MDRD_DX.DX_TYPE == \"...\")) | \\\n",
    "              ((enc_to_MDRD_DX.DX.isin(ICD10_CKD)) & (enc_to_MDRD_DX.DX_TYPE == \"...\"))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91740fa-0eaf-4824-81f8-ad5053290ab1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def estimate_eGFR_CKD(row):\n",
    "    CKD_stage = row[\"...\"]\n",
    "    if CKD_stage == \"...\":\n",
    "        return 90\n",
    "    elif CKD_stage == \"...\":\n",
    "        return 75\n",
    "    elif CKD_stage == \"...\":\n",
    "        return 45\n",
    "    elif CKD_stage == \"...\":\n",
    "        return 22.5\n",
    "    elif CKD_stage == \"...\":\n",
    "        return 15\n",
    "    else:\n",
    "        return 7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85fe23e-c4c8-4dfb-85ad-09344ec70642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc_to_MDRD_CKD.loc[:, \"...\"] = enc_to_MDRD_CKD.loc[:, \"...\"].str[-1]\n",
    "enc_to_MDRD_CKD[\"...\"] = enc_to_MDRD_CKD.progress_apply(estimate_eGFR_CKD, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e737aa-589c-48fa-9bbb-e38a9645c652",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# one encounter one prior eGFR\n",
    "enc_to_MDRD_CKD_without_dup = enc_to_MDRD_CKD.groupby(pat_id_cols)[\"...\"].min().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b5423f-281c-4d02-a554-955c503958d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc_to_MDRD = enc_to_MDRD.merge(enc_to_MDRD_CKD_without_dup, on = pat_id_cols, how = \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe1bc15-960d-4020-a55c-037f4f486b76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use 75 to represent non-CKD patients' eGFR\n",
    "enc_to_MDRD[\"...\"] = enc_to_MDRD[\"...\"].fillna(75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab51be8-60f2-4429-8415-0406423a1129",
   "metadata": {},
   "source": [
    "# Read Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164f1f62-efff-4be9-beca-3146c293772d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_and_format_DEMO(ct_names, raw_path, race_mapping):\n",
    "    DEMO_dict = read_DEMO(ct_names, raw_path)\n",
    "    processed_DEMO_dict = format_DEMO_dict(DEMO_dict, race_mapping)\n",
    "    DEMO_df = concat_dfs_to_one(processed_DEMO_dict)\n",
    "    return DEMO_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ceede0-637c-4992-bfdb-197e555efee1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read patients' demographical data\n",
    "def read_DEMO(ct_names, raw_path):\n",
    "    DEMO_dict = dict()\n",
    "    use_cols = [\"...\", \"...\", \"...\", \"...\", \"...\"]\n",
    "\n",
    "    for ct_name in ct_names:\n",
    "        \n",
    "        data_path = get_data_path(ct_name, raw_path)\n",
    "        \n",
    "        if (ct_name == \"...\") or (ct_name == \"...\") or (ct_name == \"...\") or (ct_name == \"...\"):\n",
    "            DEMO_df = pd.read_csv(data_path + \"...\", delimiter = \"...\", usecols = use_cols)\n",
    "        elif (ct_name == \"...\"):\n",
    "            DEMO_df = pd.read_csv(data_path + \"...\", delimiter = \"...\", usecols = use_cols)\n",
    "        elif (ct_name == \"...\"):\n",
    "            DEMO_df = pd.read_csv(data_path + \"...\", delimiter = \"...\")\n",
    "            DEMO_df.columns = [col.upper() for col in DEMO_df.columns] \n",
    "            DEMO_df = DEMO_df[use_cols]\n",
    "        elif (ct_name == \"...\"):\n",
    "            DEMO_df = pd.read_csv(data_path + \"...\", delimiter = \"...\", usecols = use_cols)\n",
    "        elif (ct_name == \"...\"):\n",
    "            DEMO_df = pd.read_csv(data_path + \"...\", delimiter = \"...\", \n",
    "                                           header=None, skiprows = 1, usecols=[0, 1, 2, 5, 17])\n",
    "            DEMO_df.columns = use_cols\n",
    "    \n",
    "        DEMO_df[\"...\"] = ct_name\n",
    "        DEMO_dict[ct_name] = DEMO_df\n",
    "        \n",
    "    return DEMO_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ba114a-563a-48ed-a073-968eaaeca021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_DEMO_dict(DEMO_dict, race_mapping):\n",
    "    processed_DEMO_dict = dict()\n",
    "    for ct_name, DEMO_df in DEMO_dict.items():    \n",
    "        #convert id columns to string\n",
    "        DEMO_df[[\"...\", \"...\"]] = DEMO_df[[\"...\", \"...\"]].astype(str)\n",
    "        \n",
    "        DEMO_df[\"...\"] = DEMO_df[\"...\"].replace(race_mapping)\n",
    "        \n",
    "        DEMO_df[\"...\"] = ct_name\n",
    "\n",
    "        processed_DEMO_dict[ct_name] = DEMO_df\n",
    "    return processed_DEMO_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c49cd-4758-48f1-ac16-640eb84b321e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "race_mapping = \\\n",
    "{\n",
    "    \"...\": \"...\",\n",
    "    \"...\": \"...\",\n",
    "    \"...\": \"...\",\n",
    "    \"...\": \"...\",\n",
    "    \"...\": \"...\",\n",
    "    \"...\": \"...\", \n",
    "    \"...\": \"...\",\n",
    "    \"...\": \"...\",\n",
    "    \"...\": \"...\",\n",
    "    \"...\": \"...\",\n",
    "    \"...\": \"...\",\n",
    "    \"...\": \"...\",\n",
    "    \"...\": \"...\",\n",
    "    \"...\": \"...\",\n",
    "    \"...\": \"...\",\n",
    "    \"...\": \"...\",\n",
    "    \"...\": \"...\",\n",
    "    \"...\": \"...\",\n",
    "    \"...\":  \"...\"\n",
    "}\n",
    "%store race_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a618629-bd66-444a-a760-3fc929a1705a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEMO_df = read_and_format_DEMO(ct_names, raw_path, race_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3a2ec6-b397-4988-a29b-627b57c56aad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check that all df read in successfully\n",
    "for ct_name in ct_names:\n",
    "    assert(len(DEMO_df[DEMO_df.CENTER_NAME == ct_name]) != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5d3c03-68f8-4478-a17e-8b25b4acb162",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc_to_MDRD = enc_to_MDRD.merge(DEMO_df, on = pat_id_cols, how = \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db67f648-9167-4cff-a6ab-47e2c77cb376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop rows that do not have demographics\n",
    "enc_to_MDRD = enc_to_MDRD.dropna(subset=[\"...\", \"...\", \"...\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a427f4f-5ac4-482b-83a6-5b9576738eda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop dups\n",
    "enc_to_MDRD = enc_to_MDRD.drop_duplicates(subset=pat_id_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92972816-21d8-4112-bc69-9e9ff8bc67a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_SCR(row):\n",
    "    GFR, age, gender, race = row[\"...\"], row[\"...\"], row[\"...\"], row[\"...\"]\n",
    "\n",
    "    # adjust coefficient\n",
    "    gender_factor = 0.742 if gender == \"...\" else 1\n",
    "    race_factor = 1.212 if race == \"...\" else 1\n",
    "\n",
    "    # compute SCr\n",
    "    SCR = (GFR / (175 * (age ** -0.203) * gender_factor * race_factor)) ** (1 / -1.154)\n",
    "    return SCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a535e401-2571-4241-abcb-08703fd51c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc_to_MDRD[\"...\"] = enc_to_MDRD.progress_apply(calculate_SCR, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a382e4b-8f90-4dc6-9d6a-8b07449400fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# take the lower one between SCr est and admission SCr\n",
    "# if one is nan choose the other\n",
    "enc_to_MDRD[\"...\"] = np.nanmin(enc_to_MDRD[[\"...\", \"...\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783403e1-ac32-4d5b-992c-8f0c07ad929e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "complete_df = complete_df.merge(enc_to_MDRD[pat_id_cols + [\"...\"]], \n",
    "                                on = pat_id_cols, how = \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed189db3-df30-41ab-8b88-3cd5c3ec29f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "complete_df[\"...\"] = np.where(pd.notnull(complete_df[\"...\"]), \n",
    "                                       complete_df[\"...\"], \n",
    "                                       complete_df[\"...\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec636aa-4392-4ccb-8980-a0969ae3e26b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#drop those still cannot find baseline\n",
    "complete_df = complete_df.dropna(subset=[\"...\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb939c9-371f-4885-be5a-8314b6c33490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# only keep BASELINE_SCR\n",
    "complete_df.drop([\"...\", \"...\", \"...\", \"...\",\n",
    "                 \"...\"], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e3ad65-1edc-4594-b2cf-35e984726785",
   "metadata": {},
   "source": [
    "# Preprocessing before Labeling AKI Stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6393b4-ffa8-453b-bfd2-0a5cd5dd1e76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#here we only care about SCr measurements within hospitalization, thus we filter out those history records\n",
    "# plese be note that this is only for AKI labeling, for trajectory clustering we still consider community SCr\n",
    "complete_df = complete_df[(complete_df.SPECIMEN_DATE >= complete_df.ADMIT_DATE) & \\\n",
    "                                 (complete_df.SPECIMEN_DATE <= complete_df.DISCHARGE_DATE)].copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e761c9ad-0d04-4119-a5bb-5273aff43d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort SCr based on specimen time\n",
    "complete_df = complete_df.sort_values(pat_id_cols + [\"...\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697e40d9-6a6e-4e16-a5f9-f174646c5fff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop dups based on all cols\n",
    "complete_df = complete_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144eee1b-8e70-462f-a67b-ae586845f897",
   "metadata": {},
   "source": [
    "# Label AKI Stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bba7a38-d395-4f65-b13b-ad51da8d9770",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cce158-0227-4620-b8b7-2fde96ac237b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the max SCr increment within past 2 days\n",
    "def calculate_max_diff(group):\n",
    "    max_diffs = []\n",
    "    for index, row in group.iterrows():\n",
    "        # past 2 days records\n",
    "        past_2_days = group[(group[\"...\"] >= row[\"...\"] - \\\n",
    "                             pd.Timedelta(days=2)) & (group[\"...\"] < row[\"...\"])]\n",
    "        \n",
    "        if not past_2_days.empty:\n",
    "            # difference\n",
    "            diffs = row[\"...\"] - past_2_days[\"...\"]\n",
    "            max_diff = diffs.max()\n",
    "        else:\n",
    "            max_diff = pd.NA\n",
    "        max_diffs.append(max_diff)\n",
    "    group[\"...\"] = max_diffs\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b017403-e272-4a17-b08c-13661f4ee0d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encounter_grouped = complete_df.groupby(pat_id_cols)\n",
    "groups = [group for _, group in encounter_grouped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49763dc-0483-4176-b1a4-306fcd18bee7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with Pool(cpu_count()) as p:\n",
    "    result_list = list(tqdm(p.imap(calculate_max_diff, groups), \n",
    "                         total=len(groups), \n",
    "                         desc=\"...\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161a428a-e31f-453e-a445-f9337965be1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "complete_df = pd.concat(result_list, axis = 0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53165d4-1e37-4a52-8748-6dedfc2e4d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we get the cumulative max measurements within each group\n",
    "complete_df[\"...\"] = complete_df.groupby(pat_id_cols)[\"...\"].cummax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb980005-e399-40d1-a1f4-2574a2df8048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AKI stage 1 definition part 1, absolute increment of 0.3 within 48 hours\n",
    "condition1 = (complete_df[\"...\"] >= 0.3)\n",
    "#AKI stage 1 definition part 2, fold increment\n",
    "condition2 = (complete_df[\"...\"] >= 1.5 * complete_df[\"...\"]) & \\\n",
    "(complete_df[\"...\"] < 2.0 * complete_df[\"...\"])\n",
    "#we require that onset src should be the max value until that time, so that higher stage will overwrite lower stage\n",
    "condition3 = (complete_df[\"...\"] == complete_df[\"...\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6f5d43-3be3-4249-87d4-51bc2ee6b137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measurement satisfying AKI-1 \n",
    "AKI_1 = complete_df[(condition1 | condition2) & condition3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d21fe46-a80a-4b61-9746-4a9bfd30fc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first measurement satisfying AKI-1 \n",
    "AKI_1 = AKI_1.groupby(pat_id_cols).first().reset_index().copy(deep = True)\n",
    "AKI_1.rename(columns = {\"...\": \"...\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4acd97b-0e0c-4d60-9c86-59ad79a7903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge back AKI-1 onset date\n",
    "complete_df = complete_df.merge(AKI_1[pat_id_cols + [\"...\"]], on=pat_id_cols, how=\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c710d69-097c-4104-a092-af92d64bef11",
   "metadata": {},
   "source": [
    "# Label AKI Stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68ffaab-f1a2-4b8b-b12c-e716d65234c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition4 = (complete_df[\"...\"] >= 2.0 * complete_df[\"...\"]) & \\\n",
    "(complete_df[\"...\"] < 3.0 * complete_df[\"...\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf314183-38d2-45da-89fa-5c6f59e9e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "AKI_2 = complete_df[condition4 & condition3]\n",
    "AKI_2 = AKI_2.groupby(pat_id_cols).first().reset_index().copy(deep = True)\n",
    "AKI_2.rename(columns = {\"...\": \"...\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a5984e-2e5f-49aa-93fa-7c272f1966f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge back AKI-2 onset date\n",
    "complete_df = complete_df.merge(AKI_2[pat_id_cols + [\"...\"]], on=pat_id_cols, how=\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca0a768-3523-410a-ac51-8477dd0a9133",
   "metadata": {},
   "source": [
    "# Label AKI stage 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730dd4ab-d186-4618-bafb-9fe790e79399",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition5 = (complete_df[\"...\"] >= 3.0 * complete_df[\"...\"])\n",
    "condition6 = (complete_df[\"...\"] >= 4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a38f1ac-7908-4f20-af6f-461447fa63d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "AKI_3 = complete_df[(condition5 | condition6) & condition3]\n",
    "AKI_3 = AKI_3.groupby(pat_id_cols).first().reset_index().copy(deep = True)\n",
    "AKI_3.rename(columns = {\"...\": \"...\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067e5613-0d54-4d1c-bea8-32b3cebccf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge back AKI-3 onset date\n",
    "complete_df = complete_df.merge(AKI_3[pat_id_cols + [\"...\"]], on=pat_id_cols, how=\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4269e36e-69d7-45c2-baad-f6fcd3416e37",
   "metadata": {},
   "source": [
    "# Process before Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269cd83d-4104-4a4f-8259-5b5c8472f08e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "complete_df[\"...\"] = np.where(\n",
    "    complete_df[\"...\"].notna() | complete_df[\"...\"].notna() | complete_df[\"...\"].notna(), \n",
    "    False, \n",
    "    True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b914ec0c-7396-4d2f-8183-7463a9289a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "complete_df = complete_df[[\"...\", \"...\", \"...\", \"...\", \"...\",\n",
    "                          \"...\", \"...\", \"...\", \"...\", \"...\"]].copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183c1584-d59a-4857-b123-ec615d491993",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#each encounter we only keep one row info, that is each encounter is unique\n",
    "complete_df = complete_df.drop_duplicates(pat_id_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32254bd8-bf1b-4af7-b5de-f7e0bea3c8b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "complete_df.NONAKI_SINCE_ADMIT.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08248eaf-b68a-413a-b27a-230e1f477ed5",
   "metadata": {},
   "source": [
    "# Save the AKI Onset Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13500508-da58-40d3-b66c-a06b2eb35ec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "complete_df.to_csv(\"...\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AKI_subphenotyping",
   "language": "python",
   "name": "aki_subphenotyping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
